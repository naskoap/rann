{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code for the experiments using Grid Search (the baseline comparison with no tool) on both the classification and regression datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modlules\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "RANDOM_SEED = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating elapsed time\n",
    "def print_elapsed_time(start, end):\n",
    "    elapsed_time = end - start\n",
    "    minutes = int(elapsed_time // 60)\n",
    "    seconds = int(elapsed_time % 60)\n",
    "    print(\"Elapsed time: {} minutes, {} seconds\".format(minutes, seconds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospital Readmissions (Classification)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we run grid search on our classification dataset. To do so, we have to define a grid of parameters to try, which is defined below as `param_grid`. Then, sklearn will try all combinations of these specified parameters to see which one performs best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "readmissions = pd.read_csv(\"../data/classification/readmissions_clean.csv\")\n",
    "\n",
    "# Split into X and Y\n",
    "X = readmissions.drop('readmitted', axis=1)\n",
    "y = readmissions[\"readmitted\"]\n",
    "\n",
    "# Split into train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random Forest\n",
    "rf = RandomForestClassifier(random_state=RANDOM_SEED)\n",
    "\n",
    "# Choose a parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 10, 15],\n",
    "    'max_features': [3, 5, 8, 10],\n",
    "    'n_estimators': [50, 150, 200, 300]\n",
    "}\n",
    "\n",
    "# Time grid search\n",
    "start = time.time()\n",
    "\n",
    "grid_search_classifier = GridSearchCV(estimator = rf, param_grid = param_grid)\n",
    "grid_search_classifier.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the grid search optimization took 9 minutes and 24 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 9 minutes, 24 seconds\n"
     ]
    }
   ],
   "source": [
    "# Display time elapsed\n",
    "print_elapsed_time(start,end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the optimal set of parameters that was found by the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'max_features': 3, 'n_estimators': 200}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get optimal parameters\n",
    "grid_search_classifier.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best trial has the following parameters, so now we use this optimized set to apply again to our model and get final optimization scores:\n",
    "\n",
    "`{'max_depth': 5, 'max_features': 3, 'n_estimators': 200}`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6278\n",
      "Precision: 0.6252028123309897\n",
      "Recall: 0.4974182444061962\n"
     ]
    }
   ],
   "source": [
    "# Fit model with optimal parameters\n",
    "rf = RandomForestClassifier(random_state=RANDOM_SEED, max_depth = 5, max_features = 3, n_estimators = 200)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Get performance metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car Emissions (Regression)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regression, we complete the exact same steps, but using `RandomForestRegressor` as our model instead of `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "emissions = pd.read_csv(\"../data/regression/emissions_cleaned.csv\")\n",
    "\n",
    "# Split into X and Y\n",
    "X = emissions.drop('co2_emissions', axis=1)\n",
    "y = emissions[\"co2_emissions\"]\n",
    "\n",
    "# Split into train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Random Forest\n",
    "rf = RandomForestRegressor(random_state=RANDOM_SEED)\n",
    "\n",
    "# Choose a parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [5, 7, 10, 15],\n",
    "    'max_features': [3, 5, 8, 10],\n",
    "    'n_estimators': [50, 150, 200, 300]\n",
    "}\n",
    "\n",
    "# Time grid search\n",
    "start = time.time()\n",
    "\n",
    "grid_search_regressor = GridSearchCV(estimator = rf, param_grid = param_grid)\n",
    "grid_search_regressor.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the grid search optimization took 2 minutes and 47 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2 minutes, 47 seconds\n"
     ]
    }
   ],
   "source": [
    "# Display time elapsed\n",
    "print_elapsed_time(start,end)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we view the optimal parameters found in the grid search from all combinations of the ones provided in the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 15, 'max_features': 10, 'n_estimators': 300}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get optimal parameters\n",
    "grid_search_regressor.best_params_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best trial had the following parameters, so now we plug these back in to our model to get our final metrics:\n",
    "\n",
    "`{'max_depth': 15, 'max_features': 10, 'n_estimators': 300}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.6924411810082374\n",
      "Mean Absolute Percentage Error (MAPE): 0.007012699729565289\n",
      "Mean Squared Error (MSE): 10.143196795641945\n"
     ]
    }
   ],
   "source": [
    "# Fit model with optimal parameters\n",
    "rf = RandomForestRegressor(random_state=3, max_depth = 15, max_features = 10, n_estimators = 300)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error (MAE):', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Absolute Percentage Error (MAPE):', mean_absolute_percentage_error(y_test, y_pred))\n",
    "print('Mean Squared Error (MSE):', mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
